---
layout: post
title: VMworld 2019 – Récapitulatif jour 4
category: VMware
author: lrivallain
tags: vmware vmworld french
thumb: /images/vmworld2019.png
---

![Photo Booth SII Île de France](/images/vmworld2019/day4_VMwareFrance.png)

## Deploying the VMware Cloud Provider Platform `[HBI2767BE]`

* Auteur de la notice ci-dessous: *[Ludovic Rivallain](/about/#lrivallain)*
* Speaker(s):
  * **Eiad AlAqqad**, VCPP Lead Solution Architect, VMware
  * **Milko Slavov**, Staff Engineer, VMware
* [Vidéo](https://videos.vmworld.com/global/2019/videoplayer/29354)

Cloud Provider Pod est une option qui (pourrait\|doit) être très intéressante pour déployer *from scratch*, en tant que Cloud Provider, une offre de cloud basée sur une stack VMware. Le produit prend en charge bon nombre des configurations les plus longues, complexes et sujetes à des erreurs humaines et se propose de tout automatiser avec le support des fonctions suivantes (à ce jour):

* Day 0 de tout le *SDDC* (compute, storage, network + security)
* Mise en place du *Data Recovery, Data Protection* et des solutions de migration (*vCAV*)
* Multi-tenancy (*vCD*)
* *vROPs*, *vRNI* et *vRLI* pour la supervision et la phase opérationnelle
* La mise en place du *chargeback* (coucou *vRB*)
* Multi-sites (avec contraintes)
* La gestion des containeurs via [vCD Container Service Extension](https://vmware.github.io/container-service-extension)
* Gestion des licences *vSPP* (*Usage Meter* mon amour!)
* *vRO* pour l'automatisation (le produit s'appuye d'ailleurs sur *vRO* pour l'automatisation)
* La génération de la documentation (Architecture, Planning, Ops Guides…)
* *VMware Cloud Verified* ready
* …

Avec tout de même quelques limitations annoncées:

* 64 noeuds maximum
* VXLAN ou VLAN backed network seulement
* Pas de migration possible d'un *brown field*. *Green field* seulement!
* Multi-sites avec de la latence: non supporté (metro cluster)
* Ne supporte pas le routage IP direct pour les environnements clients (configuration manuelle requise)

La version 1.6 a été devait être annoncée en Novembre (mais visiblement ce n'est pas encore le cas), avec les nouvelles fonctionnalités suivantes:

* Nouveau *designer* ([SaaS: designer.cloud.vmware.com](https://designer.cloud.vmware.com/))
* Automatisation encore plus poussée du démarrage des opérations de déploiment.
* Support garantie de *VMware Validated Design*
* Nouvelle API
* Mise à jour des composants logiciels proposés

Pour ma part j'aimerais bien tester ce type de produit mais les occasions sont rare et j'ai bien peur que par manque de souplesse, il faille sortir des sentiers battus très rapidement pour contenter les besoins spécifiques de nos clients *cloud providers*.

## 60 Minutes of Non-Uniform Memory Architecture `[HBI2278BE]`

* Auteur de la notice ci-dessous: *[Ludovic Rivallain](/about/#lrivallain)*
* Speaker(s):
  * **Frank Denneman**, Chief Technologist, CPBU, VMware
* [Vidéo](https://videos.vmworld.com/global/2019/videoplayer/29139)

… ou comment s'assomer pour finir le séjour.

Les *Deep Dive* proposés par Frank Denneman (et ses collègues) sont toujours d'un niveau technique très élevé mais d'une richesse incroyable.

Un sujet comme NUMA pourrait nécessiter des jours et des jours d'apprentissage pour être maitrisé mais la conférence proposé évoquait déjà quelques beaux chapitres avec beaucoup de pédagogie.

Le premier chapitre était consacré à l'explication d'une slide de la keynote du mardi ou il était annoncé que le projet Pacific (Faire tourner des pods K8S directement dans l'hyperviseur vSphere) permettait d'atteindre jusqu'à 30% de performances en plus que dans une VM Linux et 8% vis à vis de Kubernetes sur un Linux Baremetal… Cela méritait en effet quelques explications que je ne pourrais retranscrire correctment ici mais qui étaient étayées de démonstrations de la gestion mémoire/cpu très optimisée sur le kernel vSphere.

Un autre chapitre était consacré à expliquer comment VMware avait réussi à contourner le challenge de la faille Intel L1TF (*Side Channel Vulnerability*) tout en conservant (pour les kernels les plus récents >= 6.7u2) des performances comparables à la situation avant la découverte de cette faille. Il faut savoir que c'est un enjeu majeur de la résolution de cette faille de sécurité). La nouvelle politique de scheduling CPU de vSphere pour résoudre ce dylème s'appelle *Side Channel Aware Scheduler* (SCA).

Je passe rapidement sur le reste car c'était très dense: *vNUMA, VPD et PPDs*, alignement des *Core Per Socket*, gestion du *CPU Hot Add*… Autant de savoureux sujets qu'il est intéressant de comprendre (à défaut de les maitriser totalement) si on cherche à obtenir des performances élevées de son infrastructure de virtualisation, ou si on a des workloads spécifiques dans la consommation CPU ou mémoire.


## Next generation reference design with NSX-T part 1 and 2 `[CNET2061BE]` and `[CNET2068BE]`

* Auteur de la notice ci-dessous: *Jérémy Rossignol*
* Speaker(s):
  * **Nimish Desai**, Director Technical Product Management, VMware
* [Vidéo - Partie 1](https://videos.vmworld.com/global/2019/videoplayer/29694)
* [Vidéo - Partie 2](https://videos.vmworld.com/global/2019/videoplayer/29692)

Une conférence avancée en deux parties sur le design *single-tier* et *multi-tier* NSX-T. Je ne rentrerai pas dans les détails des designs car ici nous avons revu plusieurs usecases et quel design appliquer sur ces usecases.

Conférence très intéressante sur comment répondre à vos problématiques avec un niveau technique très poussé. Je vous conseille fortement d'aller regarder les deux vidéos de cette conférence en deux parties.

Quelques bonnes nouvelles suite à une discussion avec le speaker, Nimish Desai, NSX-T 3.0, version qui sera lancée normalement au premier semestre 2020, incluera la gestion des VRF ce qui simplifiera la vie pour les designs multi clients.


## Deploying and Designing Kubernetes with NSX-T (Openshift, PKS, PAS) `[CNET1444BE]`

* Auteur de la notice ci-dessous: *Christian Tritten*
* Speaker(s):
  * **Chhavi Nijhawan**, Product Line Marketing Manager, VMware
  * **Nikolay Nikolaev**, Open Source Networking Team Lead, VMware
* [Vidéo](https://videos.vmworld.com/global/2019/videoplayer/29837)

Session technique qui présente l'architecture de NSX-T dans Kubernetes. Un cas d'usage illustre l'utilisation de NSX-T pour gérer le réseau sur plusieurs clusters *OpenShift* et *Kubernetes PKS* simultanément, et comment mettre en place du loadbalancing L7 sur une application déployée sur plusieurs clusters.


## Run Kubernetes Consistently Across Clouds with Tanzu and Project Pacific `[KUB1840E]`

* Auteur de la notice ci-dessous: *Christian Tritten*
* Speaker(s):
  * **Michael West**, Technical Product Manager, VMware
  * **Ross Kukulinski**, Product Line Manager, VMware
  * **Tom Spoonemore**, Product Line Manager, VMware
* [Vidéo](https://videos.vmworld.com/global/2019/videoplayer/29812)

Comme on l'a vu précédemment, Kubernetes possède de nombreux atouts quand on souhaite déployer des applications conteneurisées. Le projet VMware *Tanzu* se propose de faciliter la mise en œuvre et l'exploitation de Clusters Kubernetes à l'échelle industrielle.

*Tanzu* introduit la notion de _Kubernetes grid_ qui consiste à gérer tous les clusters Kubernetes de l'entreprise, quels que soit leur mode de déploiement (sur du vSphere, via *Project Pacific*, via du PKS, etc...).

Le déploiement de clusters Kubernetes au sein de *Project Pacific* s'appuie sur la spécification _Cluster API_ supportée par un nombre croissant d'opérateurs (12 à ce jour dont : *Google Cloud, Amazon, Azure, OpenStack, IBM Cloud, WMware*)

L'outil *Tanzu Mission Control* permet via une interface web unifiée de piloter la création ou le rattachement de l'ensemble des cluster Kubernetes en mode multi-cloud. Il permet également de gérer le cycle de vie de ces clusters, via des procédures de mises à jour automatisées.


## Solutions Exchange: Stand *NetApp*

* Auteur de la notice ci-dessous: *Christian Tritten*

NetApp ne fait pas que du stockage. Ils proposent désormais d'autres types de produits:

* Kubernetes managé sur *AWS, GCP, Azure, AlibabaCloud* mais aussi *on premise* sur une [appliance hardware dédiée](https://cloud.netapp.com/kubernetes-service).
* Du stockage pour Kubernetes (*persistent volumes*)